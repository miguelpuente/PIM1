{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Avance 3: Transformación de Datos con Python"
      ],
      "metadata": {
        "id": "Qx2QNU4VGGjU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Configuración, Carga y Unificación de Datos\n",
        "El primer paso es cargar todas las fuentes de datos (CSV) y unificarlas en un único DataFrame principal para realizar las operaciones de Feature Engineering."
      ],
      "metadata": {
        "id": "24atpTmvF9rl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m1Cji9CYFzwx"
      },
      "outputs": [],
      "source": [
        "# 1 Configuración de Entorno y Carga de Archivos\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Cargar los archivos CSV\n",
        "try:\n",
        "    df_sales = pd.read_csv('sales.csv')\n",
        "    df_products = pd.read_csv('products.csv')\n",
        "    df_employees = pd.read_csv('employees.csv')\n",
        "    df_customers = pd.read_csv('customers.csv')\n",
        "    df_categories = pd.read_csv('categories.csv')\n",
        "    df_cities = pd.read_csv('cities.csv')\n",
        "    df_countries = pd.read_csv('countries.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"¡Advertencia! Asegúrate de que los archivos CSV estén cargados en el entorno de Colab.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Renombrado y estandarización de columnas\n",
        "\n",
        "df_products.rename(columns={'ProductID': 'product_id', 'Price': 'unit_price', 'CategoryID': 'category_id'}, inplace=True)\n",
        "df_categories.rename(columns={'CategoryID': 'category_id', 'CategoryName': 'category_name'}, inplace=True)\n",
        "df_employees.rename(columns={'EmployeeID': 'employee_id', 'BirthDate': 'birth_date', 'HireDate': 'hire_date'}, inplace=True)\n",
        "df_sales.rename(columns={'SalesPersonID': 'sales_person_id', 'ProductID': 'product_id', 'Quantity': 'quantity', 'Discount': 'discount', 'SalesDate': 'sales_date'}, inplace=True)\n",
        "df_customers.rename(columns={'CustomerID': 'customer_id', 'CityID': 'city_id'}, inplace=True)\n",
        "df_cities.rename(columns={'CityID': 'city_id', 'CityName': 'city_name'}, inplace=True)\n",
        "df_countries.rename(columns={'CountryID': 'country_id', 'CountryName': 'country_name'}, inplace=True)"
      ],
      "metadata": {
        "id": "OoLni_wrNvi1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. UNIFICACIÓN DEL DATASET BASE ---\n",
        "df_data = df_sales.copy()\n",
        "\n",
        "# A. Unir con Products y Categories\n",
        "df_data = pd.merge(df_data, df_products[['product_id', 'unit_price', 'category_id', 'ProductName']], on='product_id', how='left')\n",
        "df_data = pd.merge(df_data, df_categories[['category_id', 'category_name']], on='category_id', how='left')\n",
        "\n",
        "# B. Unir con Employees (para las Features de Empleados)\n",
        "df_data = pd.merge(df_data, df_employees[['employee_id', 'birth_date', 'hire_date']], left_on='sales_person_id', right_on='employee_id', how='left', suffixes=('_sale', '_emp'))\n",
        "df_data.drop(columns=['employee_id'], inplace=True)\n",
        "\n",
        "# C. Conversión de fechas a formato datetime\n",
        "date_cols = ['sales_date', 'birth_date', 'hire_date']\n",
        "for col in date_cols:\n",
        "    df_data[col] = pd.to_datetime(df_data[col], errors='coerce')\n",
        "\n",
        "\n",
        "\n",
        "print(\"DataFrame Base Unificado y Columnas Estandarizadas (snake_case).\")\n",
        "print(\"Columnas de fechas verificadas:\")\n",
        "print(df_data[date_cols].dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVdSeFnRGvBz",
        "outputId": "e7005206-fdf7-41b3-b668-74b1d5c1ae67"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Base Unificado y Columnas Estandarizadas (snake_case).\n",
            "Columnas de fechas verificadas:\n",
            "sales_date    datetime64[ns]\n",
            "birth_date    datetime64[ns]\n",
            "hire_date     datetime64[ns]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Cálculo de TotalPriceCalculated"
      ],
      "metadata": {
        "id": "RNXiItSPHaMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fórmula: $TotalPriceCalculated=(Quantity \\times UnitPrice) \\times (1-Discount)$\n",
        "\n",
        "# Justificación: El campo 'total_price' en el dataset de origen es inconsistente o nulo.\n",
        "# Se utiliza la información de 'unit_price' de la tabla 'products' para obtener el valor real.\n",
        "\n",
        "df_data['TotalPriceCalculated'] = (\n",
        "    df_data['quantity'] * df_data['unit_price']\n",
        ") * (1 - df_data['discount'])\n",
        "\n",
        "# Rellenar cualquier NaT/NaN resultante de la operación con 0.0, asumiendo ventas no registradas.\n",
        "df_data['TotalPriceCalculated'].fillna(0.0, inplace=True)\n",
        "\n",
        "print(\"\\nVerificación del cálculo de ventas totales (Top 5):\")\n",
        "print(df_data[['quantity', 'unit_price', 'discount', 'TotalPriceCalculated']].head())\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ku_Dvi5HsHs",
        "outputId": "af9444f5-3d6e-4e4a-a3ce-e8a6b9b6ca78"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verificación del cálculo de ventas totales (Top 5):\n",
            "   quantity  unit_price  discount  TotalPriceCalculated\n",
            "0         7     44.2337       0.0             309.63590\n",
            "1         7     62.5460       0.0             437.82200\n",
            "2        24     79.0184       0.0            1896.44160\n",
            "3        19     81.3167       0.2            1236.01384\n",
            "4         9     79.9780       0.0             719.80200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3121787520.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_data['TotalPriceCalculated'].fillna(0.0, inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Detección y Marcado de Outliers (IQR)\n"
      ],
      "metadata": {
        "id": "mNa6BIqXH2UV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consigna: Detecta outliers en TotalPriceCalculated utilizando el criterio del Rango Intercuartílico (IQR). Crea la columna IsOutlier.\n",
        "\n",
        "# 1. Cálculo de Cuartiles y IQR\n",
        "Q1 = df_data['TotalPriceCalculated'].quantile(0.25)\n",
        "Q3 = df_data['TotalPriceCalculated'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# 2. Definición de Límites\n",
        "LOWER_BOUND = Q1 - 1.5 * IQR\n",
        "UPPER_BOUND = Q3 + 1.5 * IQR\n",
        "\n",
        "# 3. Creación de la columna IsOutlier\n",
        "df_data['IsOutlier'] = np.where(\n",
        "    (df_data['TotalPriceCalculated'] < LOWER_BOUND) | (df_data['TotalPriceCalculated'] > UPPER_BOUND),\n",
        "    1,  # Es un outlier\n",
        "    0   # No es un outlier\n",
        ")\n",
        "\n",
        "# 4. Conteo de Outliers\n",
        "outlier_count = df_data['IsOutlier'].sum()\n",
        "\n",
        "print(f\"\\n--- Detección de Outliers (IQR) ---\")\n",
        "print(f\"Q1 (25%): {Q1:,.2f}\")\n",
        "print(f\"Q3 (75%): {Q3:,.2f}\")\n",
        "print(f\"IQR: {IQR:,.2f}\")\n",
        "print(f\"Límite Inferior (1.5*IQR): {LOWER_BOUND:,.2f}\")\n",
        "print(f\"Límite Superior (1.5*IQR): {UPPER_BOUND:,.2f}\")\n",
        "print(f\"Total de Outliers detectados: {outlier_count}\")\n",
        "\n",
        "# Justificación Técnica:\n",
        "# Se eligió el método IQR porque es robusto y menos sensible a la presencia de valores extremos\n",
        "# que podrían distorsionar la desviación estándar y la media.\n",
        "# Esto es esencial en datos de ventas, que suelen tener una distribución sesgada a la derecha\n",
        "# debido a las ventas excepcionalmente grandes."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UvLuqmeICg8",
        "outputId": "3f1835b6-701a-46aa-889f-8b442cc74355"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Detección de Outliers (IQR) ---\n",
            "Q1 (25%): 176.94\n",
            "Q3 (75%): 982.16\n",
            "IQR: 805.22\n",
            "Límite Inferior (1.5*IQR): -1,030.89\n",
            "Límite Superior (1.5*IQR): 2,189.99\n",
            "Total de Outliers detectados: 48217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Análisis Temporal de Ventas\n"
      ],
      "metadata": {
        "id": "p06GUBpEIYuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consigna 1 (Hora): Crea una nueva columna con la hora de la venta. Identifica la hora del día con más TotalPriceCalculated.\n",
        "\n",
        "# 1. Creación de la columna 'SaleHour'\n",
        "df_data['SaleHour'] = df_data['sales_date'].dt.hour\n",
        "\n",
        "# 2. Identificación de la hora pico de ventas totales\n",
        "hourly_sales = df_data.groupby('SaleHour')['TotalPriceCalculated'].sum().sort_values(ascending=False)\n",
        "hour_peak = hourly_sales.index[0]\n",
        "peak_sales_value = hourly_sales.iloc[0]\n",
        "\n",
        "print(f\"\\n--- Análisis de Hora Pico ---\")\n",
        "print(f\"Hora del día con mayor TotalPriceCalculated: {hour_peak}:00 (Ventas totales: {peak_sales_value:,.2f})\")\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0GfyzocIpdb",
        "outputId": "079edd3d-ae57-42ef-e3f5-c8137f7ee754"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Análisis de Hora Pico ---\n",
            "Hora del día con mayor TotalPriceCalculated: 16.0:00 (Ventas totales: 179,014,421.24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Consigna 2 (Clasificación): Clasifica cada venta como 'Entre semana' o 'Fin de semana'. Compara el total de ventas.\n",
        "\n",
        "# 1. Clasificación del día de la semana\n",
        "# Lunes (0) a Viernes (4) es 'Entre semana'. Sábado (5) y Domingo (6) es 'Fin de semana'.\n",
        "df_data['DayType'] = np.where(\n",
        "    df_data['sales_date'].dt.dayofweek.isin([5, 6]), # 5: Sábado, 6: Domingo\n",
        "    'Fin de semana',\n",
        "    'Entre semana'\n",
        ")\n",
        "\n",
        "# 2. Comparación de Ventas Totales\n",
        "sales_by_day_type = df_data.groupby('DayType')['TotalPriceCalculated'].sum().sort_values(ascending=False)\n",
        "winner = sales_by_day_type.index[0]\n",
        "\n",
        "print(f\"\\n--- Comparación de Ventas: Entre Semana vs. Fin de Semana ---\")\n",
        "print(sales_by_day_type.map('{:,.2f}'.format))\n",
        "\n",
        "# Conclusión Fundamentada:\n",
        "# Analizar si la concentración de ventas en 'Entre semana' vs. 'Fin de semana' justifica\n",
        "# una reasignación de personal o inventario.\n",
        "if winner == 'Entre semana':\n",
        "    print(f\"\\nConclusión: La empresa vende más en '{winner}', sugiriendo que la mayoría de los clientes son compradores habituales o compras para negocio.\")\n",
        "else:\n",
        "    print(f\"\\nConclusión: La empresa vende más en '{winner}', indicando una fuerte orientación al consumidor final o compras de 'stock' semanal.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09wG-0k-I7ID",
        "outputId": "a32525de-b728-4384-ac29-7e7958868b15"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Comparación de Ventas: Entre Semana vs. Fin de Semana ---\n",
            "DayType\n",
            "Entre semana     3,123,404,728.48\n",
            "Fin de semana    1,192,862,950.44\n",
            "Name: TotalPriceCalculated, dtype: object\n",
            "\n",
            "Conclusión: La empresa vende más en 'Entre semana', sugiriendo que la mayoría de los clientes son compradores habituales o compras para negocio.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Feature Engineering: Antigüedad del Empleado"
      ],
      "metadata": {
        "id": "73ZtcFZGJIiE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consigna: Calcula (1) Edad del empleado al momento de la contratación y (2) Años de experiencia al momento de la venta.\n",
        "\n",
        "# 1. Cálculo de la Edad al Contratar (HireDate - BirthDate)\n",
        "# Se calcula la diferencia en días y se divide por 365.25 para obtener años con precisión.\n",
        "df_data['AgeAtHire'] = (df_data['hire_date'] - df_data['birth_date']).dt.days / 365.25\n",
        "\n",
        "# 2. Cálculo de la Experiencia al Vender (SalesDate - HireDate)\n",
        "# Se calcula la diferencia en días y se divide por 365.25 para obtener años con precisión.\n",
        "df_data['ExperienceYears'] = (df_data['sales_date'] - df_data['hire_date']).dt.days / 365.25\n",
        "\n",
        "# Limpieza de valores inválidos (e.g., fechas faltantes o HireDate después de SalesDate)\n",
        "df_data['AgeAtHire'].fillna(-1, inplace=True) # Usar -1 para indicar dato faltante/inválido\n",
        "df_data['ExperienceYears'] = df_data['ExperienceYears'].apply(lambda x: x if x >= 0 else 0) # La experiencia no puede ser negativa\n",
        "\n",
        "print(f\"\\n--- Verificación de Features de Empleados (Primeras 5 filas) ---\")\n",
        "print(df_data[['sales_date', 'birth_date', 'hire_date', 'AgeAtHire', 'ExperienceYears']].head())\n",
        "\n",
        "# Justificación:\n",
        "# El uso de años decimales (división por 365.25) en lugar de un cálculo simple de año permite\n",
        "# una mayor precisión para modelos de Machine Learning, evitando la pérdida de información\n",
        "# sobre el tiempo exacto transcurrido, una práctica clave en Feature Engineering temporal."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALJlvWk-JmS8",
        "outputId": "394bc4e0-4f7d-49f5-9b85-31325229caf9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2065911985.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_data['AgeAtHire'].fillna(-1, inplace=True) # Usar -1 para indicar dato faltante/inválido\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Verificación de Features de Empleados (Primeras 5 filas) ---\n",
            "               sales_date birth_date               hire_date  AgeAtHire  \\\n",
            "0 2018-02-05 07:38:25.430 1987-01-13 2013-06-22 13:20:18.080  26.439425   \n",
            "1 2018-02-02 16:03:31.150 1951-07-07 2017-02-10 11:21:26.650  65.598905   \n",
            "2 2018-05-03 19:31:56.880 1963-04-18 2011-12-12 10:43:52.940  48.651608   \n",
            "3 2018-04-07 14:43:55.420 1956-12-13 2014-10-14 23:12:53.420  57.834360   \n",
            "4 2018-02-12 15:37:03.940 1963-12-30 2012-07-23 15:02:12.640  48.563997   \n",
            "\n",
            "   ExperienceYears  \n",
            "0         4.621492  \n",
            "1         0.977413  \n",
            "2         6.390144  \n",
            "3         3.477070  \n",
            "4         5.557837  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Preparación del Dataset Definitivo para Modelado"
      ],
      "metadata": {
        "id": "UOj2DP-iJv09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consigna: Prepara un único dataset definitivo para modelado. Incluye features calculadas. Aplica transformaciones a variables categóricas y numéricas (si es necesario). La variable objetivo (TotalPriceCalculated) no debe transformarse.\n",
        "\n",
        "# 1. Selección de Columnas Relevantes (Incluyendo Features Creadas)\n",
        "# Se incluyen también features de otras tablas (clientes, ciudades, etc.) para enriquecer el modelo.\n",
        "\n",
        "# Lista simplificada de columnas para el modelo\n",
        "features_to_keep = [\n",
        "    'TotalPriceCalculated',   # OBJETIVO (sin transformar)\n",
        "    'quantity',               # Numérica\n",
        "    'discount',               # Numérica\n",
        "    'SaleHour',               # Categórica/Ordinal (transformada)\n",
        "    'DayType',                # Categórica (transformada)\n",
        "    'IsOutlier',              # Categórica/Binaria\n",
        "    'AgeAtHire',              # Numérica (Feature Engineering)\n",
        "    'ExperienceYears',        # Numérica (Feature Engineering)\n",
        "    'ProductName',           # Categórica\n",
        "    'category_name',          # Categórica\n",
        "    'sales_person_id',        # Categórica (ID)\n",
        "    'CustomerID',            # Categórica (ID)\n",
        "    # Aquí se podrían añadir features de city_id, country_id, etc.\n",
        "]\n",
        "\n",
        "df_model = df_data[features_to_keep].copy()\n",
        "\n",
        "# 2. Transformación de Variables Categóricas (One-Hot Encoding)\n",
        "# Se utiliza One-Hot Encoding para categorías con bajo número de niveles (DayType, category_name)\n",
        "# para evitar la asunción de orden (como en Label Encoding).\n",
        "\n",
        "categorical_cols = ['DayType', 'category_name']\n",
        "df_model = pd.get_dummies(df_model, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# 3. Manejo Final de Nulos\n",
        "# Tras la limpieza y feature engineering, cualquier remanente de NaN se imputa con la media o 0,\n",
        "# dependiendo de la naturaleza de la columna.\n",
        "numeric_cols = df_model.select_dtypes(include=np.number).columns\n",
        "df_model[numeric_cols].fillna(df_model[numeric_cols].mean(), inplace=True)\n",
        "\n",
        "\n",
        "print(f\"\\n--- Dataset Definitivo para Modelado ---\")\n",
        "print(f\"Filas: {len(df_model)}, Columnas: {len(df_model.columns)}\")\n",
        "print(df_model.head())\n",
        "print(\"\\nTipos de datos del dataset final:\")\n",
        "print(df_model.dtypes)\n",
        "\n",
        "# Justificación de las Transformaciones:\n",
        "# 1. Feature Selection: Se eliminaron las columnas redundantes (e.g., 'total_price' original, fechas crudas)\n",
        "#    y se conservaron las features de mayor valor predictivo.\n",
        "# 2. One-Hot Encoding: Se aplicó a variables nominales ('DayType', 'category_name') para que el\n",
        "#    modelo de ML pueda interpretar estas características sin asumir una relación ordinal\n",
        "#    inexistente, creando un dataset totalmente numérico y listo para el entrenamiento."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kwzje5s7Jz6r",
        "outputId": "6b953cb2-0218-4f71-db84-d69174cc6ff4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Dataset Definitivo para Modelado ---\n",
            "Filas: 6758125, Columnas: 21\n",
            "   TotalPriceCalculated  quantity  discount  SaleHour  IsOutlier  AgeAtHire  \\\n",
            "0             309.63590         7       0.0       7.0          0  26.439425   \n",
            "1             437.82200         7       0.0      16.0          0  65.598905   \n",
            "2            1896.44160        24       0.0      19.0          0  48.651608   \n",
            "3            1236.01384        19       0.2      14.0          0  57.834360   \n",
            "4             719.80200         9       0.0      15.0          0  48.563997   \n",
            "\n",
            "   ExperienceYears                 ProductName  sales_person_id  CustomerID  \\\n",
            "0         4.621492            Vaccum Bag 10x13                6       27039   \n",
            "1         0.977413                    Sardines               16       25011   \n",
            "2         6.390144     Crab - Imitation Flakes               13       94024   \n",
            "3         3.477070  Smirnoff Green Apple Twist                8       73966   \n",
            "4         5.557837         Coffee - Dark Roast               10       32653   \n",
            "\n",
            "   ...  category_name_Cereals  category_name_Confections  category_name_Dairy  \\\n",
            "0  ...                  False                       True                False   \n",
            "1  ...                  False                      False                False   \n",
            "2  ...                  False                      False                False   \n",
            "3  ...                  False                      False                False   \n",
            "4  ...                  False                      False                False   \n",
            "\n",
            "   category_name_Grain  category_name_Meat  category_name_Poultry  \\\n",
            "0                False               False                  False   \n",
            "1                 True               False                  False   \n",
            "2                False               False                  False   \n",
            "3                False               False                  False   \n",
            "4                False               False                   True   \n",
            "\n",
            "   category_name_Produce  category_name_Seafood  category_name_Shell fish  \\\n",
            "0                  False                  False                     False   \n",
            "1                  False                  False                     False   \n",
            "2                   True                  False                     False   \n",
            "3                  False                   True                     False   \n",
            "4                  False                  False                     False   \n",
            "\n",
            "   category_name_Snails  \n",
            "0                 False  \n",
            "1                 False  \n",
            "2                 False  \n",
            "3                 False  \n",
            "4                 False  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            "Tipos de datos del dataset final:\n",
            "TotalPriceCalculated         float64\n",
            "quantity                       int64\n",
            "discount                     float64\n",
            "SaleHour                     float64\n",
            "IsOutlier                      int64\n",
            "AgeAtHire                    float64\n",
            "ExperienceYears              float64\n",
            "ProductName                   object\n",
            "sales_person_id                int64\n",
            "CustomerID                     int64\n",
            "DayType_Fin de semana           bool\n",
            "category_name_Cereals           bool\n",
            "category_name_Confections       bool\n",
            "category_name_Dairy             bool\n",
            "category_name_Grain             bool\n",
            "category_name_Meat              bool\n",
            "category_name_Poultry           bool\n",
            "category_name_Produce           bool\n",
            "category_name_Seafood           bool\n",
            "category_name_Shell fish        bool\n",
            "category_name_Snails            bool\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3619369719.py:36: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_model[numeric_cols].fillna(df_model[numeric_cols].mean(), inplace=True)\n"
          ]
        }
      ]
    }
  ]
}